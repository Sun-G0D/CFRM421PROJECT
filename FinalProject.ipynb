{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd787ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f72eaa3",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb84ac",
   "metadata": {},
   "source": [
    "The goal of our project is to predict the price of Oil futures two minutes after release. \n",
    "\n",
    "• What is the data that you are using? What is the original data source if known?\n",
    "\n",
    "• What does an instance in your data represent (e.g. a person, a transaction, etc.)? How many\n",
    "instances are there?\n",
    "\n",
    "• What is the target variable you are trying to predict?\n",
    "\n",
    "• What are the features used to predict it? Give a few examples of the features.\n",
    "\n",
    "• Provide any additional relevant information about your data if known (e.g. what is the time\n",
    "period, what place is it collected from, etc.\n",
    "\n",
    "Data will be from jan 1 2012 - jan 1 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b187c5",
   "metadata": {},
   "source": [
    "# Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99bc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_t-60</th>\n",
       "      <th>High_t-60</th>\n",
       "      <th>Low_t-60</th>\n",
       "      <th>Open_t-60</th>\n",
       "      <th>Volume_t-60</th>\n",
       "      <th>Close_t-59</th>\n",
       "      <th>High_t-59</th>\n",
       "      <th>Low_t-59</th>\n",
       "      <th>Open_t-59</th>\n",
       "      <th>Volume_t-59</th>\n",
       "      <th>...</th>\n",
       "      <th>High_t1</th>\n",
       "      <th>Low_t1</th>\n",
       "      <th>Open_t1</th>\n",
       "      <th>Volume_t1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Previous</th>\n",
       "      <th>Weekly Net Import</th>\n",
       "      <th>Weekly Production</th>\n",
       "      <th>Open_t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.46</td>\n",
       "      <td>105.56</td>\n",
       "      <td>105.44</td>\n",
       "      <td>105.56</td>\n",
       "      <td>514.0</td>\n",
       "      <td>105.46</td>\n",
       "      <td>105.52</td>\n",
       "      <td>105.45</td>\n",
       "      <td>105.46</td>\n",
       "      <td>323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.48</td>\n",
       "      <td>105.21</td>\n",
       "      <td>105.33</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>-400000.0</td>\n",
       "      <td>57869000.0</td>\n",
       "      <td>39151000.0</td>\n",
       "      <td>105.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.82</td>\n",
       "      <td>98.89</td>\n",
       "      <td>98.77</td>\n",
       "      <td>98.88</td>\n",
       "      <td>401.0</td>\n",
       "      <td>98.78</td>\n",
       "      <td>98.84</td>\n",
       "      <td>98.73</td>\n",
       "      <td>98.82</td>\n",
       "      <td>232.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.55</td>\n",
       "      <td>98.44</td>\n",
       "      <td>98.44</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>60529000.0</td>\n",
       "      <td>39137000.0</td>\n",
       "      <td>98.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.52</td>\n",
       "      <td>105.53</td>\n",
       "      <td>105.46</td>\n",
       "      <td>105.47</td>\n",
       "      <td>187.0</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.53</td>\n",
       "      <td>105.48</td>\n",
       "      <td>105.52</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.27</td>\n",
       "      <td>105.40</td>\n",
       "      <td>983.0</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>62671000.0</td>\n",
       "      <td>38990000.0</td>\n",
       "      <td>105.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.65</td>\n",
       "      <td>104.67</td>\n",
       "      <td>104.56</td>\n",
       "      <td>104.60</td>\n",
       "      <td>484.0</td>\n",
       "      <td>104.65</td>\n",
       "      <td>104.65</td>\n",
       "      <td>104.57</td>\n",
       "      <td>104.64</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.40</td>\n",
       "      <td>104.35</td>\n",
       "      <td>104.37</td>\n",
       "      <td>292.0</td>\n",
       "      <td>2900000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>63658000.0</td>\n",
       "      <td>38976000.0</td>\n",
       "      <td>104.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.45</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.43</td>\n",
       "      <td>108.43</td>\n",
       "      <td>37.0</td>\n",
       "      <td>108.44</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.43</td>\n",
       "      <td>108.46</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.63</td>\n",
       "      <td>108.48</td>\n",
       "      <td>108.62</td>\n",
       "      <td>567.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>2900000.0</td>\n",
       "      <td>62412000.0</td>\n",
       "      <td>39466000.0</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close_t-60  High_t-60  Low_t-60  Open_t-60  Volume_t-60  Close_t-59  \\\n",
       "0      105.46     105.56    105.44     105.56        514.0      105.46   \n",
       "1       98.82      98.89     98.77      98.88        401.0       98.78   \n",
       "2      105.52     105.53    105.46     105.47        187.0      105.50   \n",
       "3      104.65     104.67    104.56     104.60        484.0      104.65   \n",
       "4      108.45     108.46    108.43     108.43         37.0      108.44   \n",
       "\n",
       "   High_t-59  Low_t-59  Open_t-59  Volume_t-59  ...  High_t1  Low_t1  Open_t1  \\\n",
       "0     105.52    105.45     105.46        323.0  ...   105.48  105.21   105.33   \n",
       "1      98.84     98.73      98.82        232.0  ...    98.55   98.44    98.44   \n",
       "2     105.53    105.48     105.52        121.0  ...   105.50  105.27   105.40   \n",
       "3     104.65    104.57     104.64        201.0  ...   104.40  104.35   104.37   \n",
       "4     108.46    108.43     108.46         26.0  ...   108.63  108.48   108.62   \n",
       "\n",
       "   Volume_t1     Actual   Forecast   Previous  Weekly Net Import  \\\n",
       "0     2052.0  2500000.0  1100000.0  -400000.0         57869000.0   \n",
       "1      473.0  1700000.0  1800000.0  2500000.0         60529000.0   \n",
       "2      983.0  2100000.0  2000000.0  1700000.0         62671000.0   \n",
       "3      292.0  2900000.0  2000000.0  2100000.0         63658000.0   \n",
       "4      567.0  2000000.0  1300000.0  2900000.0         62412000.0   \n",
       "\n",
       "   Weekly Production  Open_t0  \n",
       "0         39151000.0   105.24  \n",
       "1         39137000.0    98.40  \n",
       "2         38990000.0   105.35  \n",
       "3         38976000.0   104.34  \n",
       "4         39466000.0   108.60  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace this with your own path to the CSV file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"C:/Users/miaca/OneDrive/Desktop/full_data.csv\")\n",
    "#This removes all t2, t1, and t0 columns besides open_t0. This is the data we would have if we predicted close_t2 at t0 \n",
    "feature_cols = [col for col in df.columns if '_t2' not in col and 't_1' not in col and 't_0' not in col and col not in ['Close_t2', 'Release_Datetime', 'Date']] + ['Open_t0']\n",
    "feature_cols = [ col for col in feature_cols if col not in ['Unnamed: 0', 'Release Date']]\n",
    "X = df[feature_cols]\n",
    "y = df['Close_t2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2480d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train, test and validation sets. Splitting the data \n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "#Scaling the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fe37d",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25aba02",
   "metadata": {},
   "source": [
    "## Linear Regression / LASSO (Mia Callahan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e10897",
   "metadata": {},
   "source": [
    "Running a linear regression acts as a baseline for our other models. We expect that the linear regression will not perform well, as the data likely has non-linear relationships. The bias-variance tradeoff likely will lead the linear regression to underfit the data as it is a very basic model. However, it will be interesting to see how it performs especially in comparison to the more complex models we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6cfb67ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71.71177474402737,\n",
       " array([-2.41949041e+01, -4.27718140e+00, -1.60463881e+00,  5.30702272e+00,\n",
       "        -2.30654833e-04,  6.24477984e+00, -3.16396471e+00, -4.62059947e+00,\n",
       "         2.71282307e+01, -1.30317313e-03,  9.98514319e+00, -5.19220377e-01,\n",
       "        -7.00086529e-01,  3.43233614e-01,  1.17903759e-02,  1.20060990e+01,\n",
       "        -3.40093055e+00,  3.25519133e+00, -8.73553350e+00,  1.26126065e-02,\n",
       "         1.23391459e+01,  4.11215371e+00, -3.14744128e+00, -7.64907093e+00,\n",
       "        -6.17136736e-03,  1.39148850e+00, -6.32265073e-01, -5.77784890e+00,\n",
       "        -1.27345905e+01, -9.95758960e-03,  2.52536186e-01,  1.28642430e+01,\n",
       "        -6.02304604e-01, -5.42731743e+00,  4.00473708e-04,  6.88779083e+00,\n",
       "        -1.32449768e+00,  7.35996211e+00, -1.03044733e+01, -9.20374442e-03,\n",
       "        -1.80850778e+01, -9.21455725e+00,  8.67656659e+00, -7.12266756e+00,\n",
       "         1.31958508e-02, -1.69146534e+01, -7.69058363e+00,  1.87691512e+00,\n",
       "         1.90484303e+01,  8.96623830e-03, -8.21226311e+00,  6.67370185e-02,\n",
       "         1.20617788e+01,  1.42557828e+01, -3.69660382e-05, -1.58550478e+01,\n",
       "         2.32417626e+00,  6.04888953e-01, -3.23693578e-02, -4.81602587e-03,\n",
       "         1.67437279e+01, -2.27005248e+00, -8.93159544e+00,  2.17685860e+01,\n",
       "        -1.31836969e-02,  9.10211241e+00, -1.20217511e+01,  3.11423688e+00,\n",
       "        -1.05091677e+01,  2.68380854e-03,  1.10093318e+01,  7.20381401e+00,\n",
       "        -8.76215365e+00, -3.04439315e+00, -9.02815674e-03,  4.09454740e-01,\n",
       "        -4.60538133e+00, -9.39754779e+00, -4.36364113e+00, -7.63012999e-03,\n",
       "        -2.62611636e+01, -4.20408425e+00, -5.74235320e+00,  1.31881489e+01,\n",
       "        -4.91939253e-03, -7.45265630e+00,  4.42664539e+00,  7.98371620e+00,\n",
       "         2.41315348e+01,  8.49789020e-03,  5.64374820e+00, -7.60188558e+00,\n",
       "        -2.33519994e+00,  4.70790974e+00,  7.09660192e-03, -6.16206283e+00,\n",
       "         3.42638702e+00, -1.03357621e+01,  6.07889647e+00,  4.08858534e-03,\n",
       "         3.95455961e+00, -1.30923654e+00,  5.14007572e-01,  8.47434471e+00,\n",
       "         2.64919439e-03,  4.70794858e+00, -1.07182146e+01, -7.06784110e+00,\n",
       "         5.77466800e+00, -5.99215923e-03,  1.30693423e+00,  1.11231504e+01,\n",
       "        -5.18281253e-01,  2.59785270e+00, -3.28591079e-03, -1.55924918e+01,\n",
       "        -2.25606165e-01,  1.01457919e+01, -1.04801217e+01,  7.56595023e-03,\n",
       "        -1.60794026e+00,  7.70737786e+00, -5.33772519e+00,  2.29178181e+00,\n",
       "         2.43251154e-03, -1.18587319e+01,  9.61638699e+00,  6.19150413e+00,\n",
       "        -4.89374830e+00, -1.32938209e-02,  1.57485796e+01,  4.70541820e+00,\n",
       "         2.50836826e+00,  1.08773432e+00,  1.04983875e-02,  6.80468545e+00,\n",
       "        -5.67848812e+00, -4.31642763e+00, -1.32009358e+01, -1.06234919e-02,\n",
       "         1.08399473e+01, -6.73293737e+00, -3.32965879e+00,  5.72611747e-01,\n",
       "         3.63840977e-03, -1.14407879e+01,  3.27271757e+00, -3.18916252e+00,\n",
       "        -4.70023470e+00, -2.23151661e-03,  7.85264528e+00,  1.75642929e+00,\n",
       "         3.17177242e+00,  1.13470010e+01,  2.42015084e-03,  1.60374186e+01,\n",
       "        -1.10002939e+00, -3.30537606e+00, -8.75179480e+00,  1.97625068e-03,\n",
       "         1.32468588e+01,  5.67720862e+00,  5.27900410e+00, -2.13050732e+01,\n",
       "         1.65051201e-03, -7.38517438e+00,  2.80100849e+00, -4.51496368e+00,\n",
       "        -1.91005649e+01, -6.42882909e-03,  5.40072586e+00,  2.15921856e+00,\n",
       "         4.93011259e-01,  7.36883675e+00, -9.14740453e-03, -1.70253019e+00,\n",
       "         6.62785444e+00,  3.63497245e+00, -7.83972932e+00, -1.25678317e-04,\n",
       "         4.93663366e+00,  2.42486580e+00, -2.26495734e+00, -8.23726105e+00,\n",
       "        -6.10380401e-03, -5.40571929e+00,  3.55147290e+00,  9.12853244e+00,\n",
       "        -8.49518842e+00,  4.70496218e-03, -1.29372455e+01, -2.22295398e+00,\n",
       "         3.49630362e+00, -2.98493042e+00,  8.67195609e-04,  1.12920494e+01,\n",
       "         2.72286707e-01, -1.17445084e+01,  1.25118331e+01,  8.64489025e-03,\n",
       "        -1.38070958e+01,  9.21770265e+00,  5.83591904e-01, -5.65678689e+00,\n",
       "        -1.07635505e-02,  2.64335097e+00, -4.86820917e+00, -7.91937677e+00,\n",
       "         1.25758592e+01,  3.48895338e-03,  5.45876628e+00, -9.06001988e+00,\n",
       "         5.37093645e+00,  6.38814440e+00,  3.49435474e-03,  1.76541037e+01,\n",
       "        -1.12335712e+00,  1.58514174e+00, -9.73124128e-02,  3.28233715e-03,\n",
       "        -3.93048394e-01,  1.98725508e+00, -2.35365103e+00, -2.28676013e+01,\n",
       "        -1.49051835e-03,  1.87267647e+01,  2.49030127e+00,  6.71974024e+00,\n",
       "         1.12663825e+00,  9.49534255e-03,  9.23041624e+00,  9.35931258e+00,\n",
       "        -9.54024944e+00, -2.44427873e+01, -2.03939840e-02, -1.27565558e+01,\n",
       "         1.67276386e+00,  8.85679036e+00, -2.03746703e+01,  8.19730170e-03,\n",
       "        -1.78146145e+00, -2.47259851e+00, -4.77411418e+00,  1.31341444e+01,\n",
       "        -3.89143760e-03,  5.75287170e+00,  2.32005865e+00,  3.68273132e+00,\n",
       "         3.64591935e+00,  6.90264212e-03, -9.13054792e+00,  3.82447637e-01,\n",
       "         1.30946756e+00, -1.17493055e+01, -5.35305518e-03, -1.17128507e+01,\n",
       "        -7.30852977e+00, -1.19600441e+00,  1.75582293e+01, -6.05667834e-03,\n",
       "         6.98645350e+00,  3.06050638e+00, -6.45916852e+00,  1.80336336e+01,\n",
       "        -1.07568356e-03, -7.75634774e+00, -1.38755540e+00, -4.12862718e+00,\n",
       "        -1.55064318e+00,  4.15469135e-03,  7.84940196e+00,  5.62409934e+00,\n",
       "         1.37102711e+00,  4.23599390e+00,  2.19016353e-03, -8.85799568e+00,\n",
       "         7.66825693e+00, -5.40155083e+00, -1.01535252e+01, -1.45564204e-02,\n",
       "        -1.15563684e+01, -7.15831115e+00,  8.73378694e-01,  9.19186643e+00,\n",
       "         7.83406646e-03, -8.65270262e-01,  3.68531712e+00,  4.27198408e+00,\n",
       "         9.92863216e+00,  2.10899968e-03,  1.42229956e+01, -8.98710899e+00,\n",
       "         9.82135177e+00, -2.26273129e+00,  9.85440695e-03,  1.23979477e+00,\n",
       "        -1.34616072e+01,  3.43234365e-01, -8.75953847e+00,  7.05622194e-03,\n",
       "         2.83962198e+00,  4.13058621e+00,  2.73891914e+00,  1.38770765e+00,\n",
       "         5.18313873e-03,  1.99605639e+01, -4.72153553e+00,  3.45881055e+00,\n",
       "        -3.50414002e+00,  1.05333732e-02,  2.41245619e-03, -1.58483189e-03,\n",
       "        -2.71833302e-03, -2.94252215e-03, -6.64023431e-03,  1.38770765e+00]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting a linear regression model\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "linmodel = LinearRegression()\n",
    "linmodel.fit(X_train_scaled, y_train)\n",
    "linmodel.intercept_, linmodel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b09989",
   "metadata": {},
   "source": [
    "Because there are so many features, we can see that the list of coefficients is very long. It is likely that the linear reegression will overfit because it will try to fit all of the features, even if they are not relevant. After seeing performance, we will reduce the number of features to see if this improves out of sample performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0717698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 0.16\n",
      "R^2 on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "# see how it performs on out of sample data\n",
    "y_hat = linmodel.predict(X_test_scaled)\n",
    "error = np.sqrt(np.mean((y_hat - y_test) ** 2))\n",
    "print(f\"RMSE on test set: {error:.2f}\")\n",
    "#print r2 score\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "print(f\"R^2 on test set: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a8923",
   "metadata": {},
   "source": [
    "The RMSE is quite low, at .16. Additionally, 100 percent of the variance can be explained by the model. However, with only 300 observations, even though there was good out of sample performance, it is possible that the model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479db4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.641e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.102e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.061e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.254e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.234e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.01\n",
      "[1000000000000000000000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000000000000000000000, 10000000000000000000000000000000000000000000000000000000000, 1000000000000000000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000000000000000000, 10000000000000000000000000000000000000000000000000000000, 1000000000000000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000000000000000, 10000000000000000000000000000000000000000000000000000, 1000000000000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000000000000, 10000000000000000000000000000000000000000000000000, 1000000000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000000000, 10000000000000000000000000000000000000000000000, 1000000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000000, 10000000000000000000000000000000000000000000, 1000000000000000000000000000000000000000000, 100000000000000000000000000000000000000000, 10000000000000000000000000000000000000000, 1000000000000000000000000000000000000000, 100000000000000000000000000000000000000, 10000000000000000000000000000000000000, 1000000000000000000000000000000000000, 100000000000000000000000000000000000, 10000000000000000000000000000000000, 1000000000000000000000000000000000, 100000000000000000000000000000000, 10000000000000000000000000000000, 1000000000000000000000000000000, 100000000000000000000000000000, 10000000000000000000000000000, 1000000000000000000000000000, 100000000000000000000000000, 10000000000000000000000000, 1000000000000000000000000, 100000000000000000000000, 10000000000000000000000, 1000000000000000000000, 100000000000000000000, 10000000000000000000, 1000000000000000000, 100000000000000000, 10000000000000000, 1000000000000000, 100000000000000, 10000000000000, 1000000000000, 100000000000, 10000000000, 1000000000, 100000000, 10000000, 1000000, 100000, 10000, 1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07, 1e-08, 1e-09, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15, 1e-16, 1e-17, 1e-18, 1e-19, 1e-20, 1e-21, 1e-22, 1e-23, 1e-24, 1e-25, 1e-26, 1e-27, 1e-28, 1e-29, 1e-30, 1e-31, 1e-32, 1e-33, 1e-34, 1e-35, 1e-36, 1e-37, 1e-38, 1e-39, 1e-40, 1e-41, 1e-42, 1e-43, 1e-44, 1e-45, 1e-46, 1e-47, 1e-48, 1e-49, 1e-50, 1e-51, 1e-52, 1e-53, 1e-54, 1e-55, 1e-56, 1e-57, 1e-58, 1e-59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+01, tolerance: 2.457e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#lasso regression with alpha selection using cross-validation\n",
    "from sklearn.linear_model import Lasso\n",
    "mses = []\n",
    "best_mse = float('inf')\n",
    "best_alpha = None\n",
    "alphas = [10**(-x) for x in range(-60, 60)]  # This generates [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha,  random_state=42)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    mse = mean_squared_error(y_val, lasso.predict(X_val_scaled))\n",
    "    mses.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_alpha = alpha\n",
    "print(f\"Best alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bf95e",
   "metadata": {},
   "source": [
    "The best alpha is 0.01, so we will use this to fit the new lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e6bc6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set with Lasso: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.978e+01, tolerance: 2.757e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_best = Lasso(alpha=best_alpha, random_state=42)\n",
    "lasso_best.fit(X_train_scaled, y_train)\n",
    "# see how it performs on out of sample data\n",
    "y_hat_lasso = lasso_best.predict(X_test_scaled)\n",
    "error_lasso = np.sqrt(np.mean((y_hat_lasso - y_test) ** 2))\n",
    "print(f\"RMSE on test set with Lasso: {error_lasso:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71470d31",
   "metadata": {},
   "source": [
    "The RMSE of the lasso model is higher than the linear regression at .41. This is likely because the LASSO model reduces the number of features the model has to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de05c0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d234fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c7de95",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda88ff",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fb153",
   "metadata": {},
   "source": [
    "## One more model I forget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004ec4c",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4170d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
