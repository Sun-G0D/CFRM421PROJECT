{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd787ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f72eaa3",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb84ac",
   "metadata": {},
   "source": [
    "What is the goal of your project?\n",
    "\n",
    "• What is the data that you are using? What is the original data source if known?\n",
    "\n",
    "• What does an instance in your data represent (e.g. a person, a transaction, etc.)? How many\n",
    "instances are there?\n",
    "\n",
    "• What is the target variable you are trying to predict?\n",
    "\n",
    "• What are the features used to predict it? Give a few examples of the features.\n",
    "\n",
    "• Provide any additional relevant information about your data if known (e.g. what is the time\n",
    "period, what place is it collected from, etc.\n",
    "\n",
    "Data will be from jan 1 2012 - jan 1 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b187c5",
   "metadata": {},
   "source": [
    "# Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99bc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_t-60</th>\n",
       "      <th>High_t-60</th>\n",
       "      <th>Low_t-60</th>\n",
       "      <th>Open_t-60</th>\n",
       "      <th>Volume_t-60</th>\n",
       "      <th>Close_t-59</th>\n",
       "      <th>High_t-59</th>\n",
       "      <th>Low_t-59</th>\n",
       "      <th>Open_t-59</th>\n",
       "      <th>Volume_t-59</th>\n",
       "      <th>...</th>\n",
       "      <th>High_t1</th>\n",
       "      <th>Low_t1</th>\n",
       "      <th>Open_t1</th>\n",
       "      <th>Volume_t1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Previous</th>\n",
       "      <th>Weekly Net Import</th>\n",
       "      <th>Weekly Production</th>\n",
       "      <th>Open_t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.46</td>\n",
       "      <td>105.56</td>\n",
       "      <td>105.44</td>\n",
       "      <td>105.56</td>\n",
       "      <td>514.0</td>\n",
       "      <td>105.46</td>\n",
       "      <td>105.52</td>\n",
       "      <td>105.45</td>\n",
       "      <td>105.46</td>\n",
       "      <td>323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.48</td>\n",
       "      <td>105.21</td>\n",
       "      <td>105.33</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>-400000.0</td>\n",
       "      <td>57869000.0</td>\n",
       "      <td>39151000.0</td>\n",
       "      <td>105.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.82</td>\n",
       "      <td>98.89</td>\n",
       "      <td>98.77</td>\n",
       "      <td>98.88</td>\n",
       "      <td>401.0</td>\n",
       "      <td>98.78</td>\n",
       "      <td>98.84</td>\n",
       "      <td>98.73</td>\n",
       "      <td>98.82</td>\n",
       "      <td>232.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.55</td>\n",
       "      <td>98.44</td>\n",
       "      <td>98.44</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>60529000.0</td>\n",
       "      <td>39137000.0</td>\n",
       "      <td>98.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.52</td>\n",
       "      <td>105.53</td>\n",
       "      <td>105.46</td>\n",
       "      <td>105.47</td>\n",
       "      <td>187.0</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.53</td>\n",
       "      <td>105.48</td>\n",
       "      <td>105.52</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.27</td>\n",
       "      <td>105.40</td>\n",
       "      <td>983.0</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>62671000.0</td>\n",
       "      <td>38990000.0</td>\n",
       "      <td>105.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.65</td>\n",
       "      <td>104.67</td>\n",
       "      <td>104.56</td>\n",
       "      <td>104.60</td>\n",
       "      <td>484.0</td>\n",
       "      <td>104.65</td>\n",
       "      <td>104.65</td>\n",
       "      <td>104.57</td>\n",
       "      <td>104.64</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.40</td>\n",
       "      <td>104.35</td>\n",
       "      <td>104.37</td>\n",
       "      <td>292.0</td>\n",
       "      <td>2900000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>63658000.0</td>\n",
       "      <td>38976000.0</td>\n",
       "      <td>104.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.45</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.43</td>\n",
       "      <td>108.43</td>\n",
       "      <td>37.0</td>\n",
       "      <td>108.44</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.43</td>\n",
       "      <td>108.46</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.63</td>\n",
       "      <td>108.48</td>\n",
       "      <td>108.62</td>\n",
       "      <td>567.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>2900000.0</td>\n",
       "      <td>62412000.0</td>\n",
       "      <td>39466000.0</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close_t-60  High_t-60  Low_t-60  Open_t-60  Volume_t-60  Close_t-59  \\\n",
       "0      105.46     105.56    105.44     105.56        514.0      105.46   \n",
       "1       98.82      98.89     98.77      98.88        401.0       98.78   \n",
       "2      105.52     105.53    105.46     105.47        187.0      105.50   \n",
       "3      104.65     104.67    104.56     104.60        484.0      104.65   \n",
       "4      108.45     108.46    108.43     108.43         37.0      108.44   \n",
       "\n",
       "   High_t-59  Low_t-59  Open_t-59  Volume_t-59  ...  High_t1  Low_t1  Open_t1  \\\n",
       "0     105.52    105.45     105.46        323.0  ...   105.48  105.21   105.33   \n",
       "1      98.84     98.73      98.82        232.0  ...    98.55   98.44    98.44   \n",
       "2     105.53    105.48     105.52        121.0  ...   105.50  105.27   105.40   \n",
       "3     104.65    104.57     104.64        201.0  ...   104.40  104.35   104.37   \n",
       "4     108.46    108.43     108.46         26.0  ...   108.63  108.48   108.62   \n",
       "\n",
       "   Volume_t1     Actual   Forecast   Previous  Weekly Net Import  \\\n",
       "0     2052.0  2500000.0  1100000.0  -400000.0         57869000.0   \n",
       "1      473.0  1700000.0  1800000.0  2500000.0         60529000.0   \n",
       "2      983.0  2100000.0  2000000.0  1700000.0         62671000.0   \n",
       "3      292.0  2900000.0  2000000.0  2100000.0         63658000.0   \n",
       "4      567.0  2000000.0  1300000.0  2900000.0         62412000.0   \n",
       "\n",
       "   Weekly Production  Open_t0  \n",
       "0         39151000.0   105.24  \n",
       "1         39137000.0    98.40  \n",
       "2         38990000.0   105.35  \n",
       "3         38976000.0   104.34  \n",
       "4         39466000.0   108.60  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace this with your own path to the CSV file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"C:/Users/miaca/OneDrive/Desktop/full_data.csv\")\n",
    "#This removes all t2, t1, and t0 columns besides open_t0. This is the data we would have if we predicted close_t2 at t0 \n",
    "feature_cols = [col for col in df.columns if '_t2' not in col and 't_1' not in col and 't_0' not in col and col not in ['Close_t2', 'Release_Datetime', 'Date']] + ['Open_t0']\n",
    "feature_cols = [ col for col in feature_cols if col not in ['Unnamed: 0', 'Release Date']]\n",
    "X = df[feature_cols]\n",
    "y = df['Close_t2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2480d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train, test and validation sets. We do not use a time series split because there are no lags from previous days\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "#Scaling the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fe37d",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25aba02",
   "metadata": {},
   "source": [
    "## Linear Regression (Mia Callahan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e10897",
   "metadata": {},
   "source": [
    "Running a linear regression acts as a baseline for our other models. We expect that the linear regression will not perform well, as the data likely has non-linear relationships. The bias-variance tradeoff likely will lead the linear regression to underfit the data as it is a very basic model. However, it will be interesting to see how it performs especially in comparison to the more complex models we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cfb67ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71.4874658869396,\n",
       " array([-2.00072143e+01, -6.68882640e+00, -5.35274550e+00,  9.37945751e+00,\n",
       "        -1.13250550e-02,  1.52769152e+01, -6.29674700e+00, -6.03521120e+00,\n",
       "         2.65086500e+01,  4.76741888e-03,  9.10818650e+00,  3.73146878e+00,\n",
       "         2.12625724e+00, -6.58658545e+00,  4.82749805e-03,  2.14260603e+00,\n",
       "        -2.06221345e+00,  6.19040633e+00, -1.29745818e+01,  1.73938786e-02,\n",
       "         1.40787867e+01,  5.91496960e+00, -6.30662228e+00, -4.37616719e+00,\n",
       "        -6.94229144e-03,  8.60196737e+00,  4.19776264e+00, -6.28167265e+00,\n",
       "        -1.33836764e+01, -1.62233620e-02, -7.57823791e+00,  1.39004063e+01,\n",
       "         1.76065041e+00, -1.71513787e+01,  1.00448962e-02, -8.28304982e-01,\n",
       "        -1.51552968e+00,  1.00615305e+01, -5.65567905e+00, -1.62648325e-02,\n",
       "        -1.63127999e+01, -1.41814038e+01,  1.09544943e+01,  4.24595929e+00,\n",
       "         2.31471066e-02, -1.53045238e+01, -7.53926326e+00,  6.99862951e+00,\n",
       "         1.30030901e+01,  1.02421070e-02, -7.27599060e+00, -1.06491053e-01,\n",
       "         1.14721362e+01,  1.03854011e+01, -3.69799272e-03, -1.18442661e+01,\n",
       "         4.78261289e+00, -1.90287097e+00,  1.47113820e+00, -2.84223830e-03,\n",
       "         2.09432270e+01, -1.88307489e+00, -1.32124036e+01,  1.65194049e+01,\n",
       "        -2.10429770e-02,  3.69643423e+00, -1.28450137e+01,  7.62539957e+00,\n",
       "        -1.52517587e+01,  1.36645016e-02,  1.72681037e+01,  8.46628561e+00,\n",
       "        -1.65941918e+01,  4.08109428e+00, -6.58411429e-03,  1.95306721e+00,\n",
       "        -5.86335090e+00, -1.49460754e+01, -2.69547371e+00, -1.69515978e-02,\n",
       "        -1.87576755e+01, -7.58668082e+00, -7.19666435e+00,  1.51402685e+01,\n",
       "        -7.03544477e-03, -3.41324995e+00, -1.01421494e+00,  3.79776372e+00,\n",
       "         2.45473670e+01,  1.35969990e-02,  1.83740301e+01, -7.82740541e+00,\n",
       "        -3.32917007e+00,  9.94532673e+00,  1.02146581e-02, -1.11276438e+01,\n",
       "         2.93908152e+00, -7.49380129e+00, -9.61437050e+00, -3.89424671e-03,\n",
       "        -1.13360591e+01, -1.71634707e-01, -6.65976413e-01,  1.35945287e+01,\n",
       "         3.55955912e-03,  6.79817033e-02, -8.12734922e+00, -2.12790021e-01,\n",
       "         1.62904034e+01,  4.09964054e-03, -1.58295812e+00,  1.38332524e+01,\n",
       "        -2.98705779e+00,  1.12079084e+00, -6.13076725e-03, -2.05143618e+01,\n",
       "         4.70219973e-01,  1.14433939e+01, -9.95553885e+00,  7.65649091e-03,\n",
       "        -6.09532035e+00,  9.42306491e+00, -4.85973500e+00,  5.76861108e+00,\n",
       "         6.36389823e-03, -2.31752377e+01,  1.44473144e+01,  4.42943130e+00,\n",
       "        -1.31074005e+00, -2.49872399e-02,  4.31184881e+00,  1.03697711e+01,\n",
       "         9.11466207e+00,  4.86614129e+00,  2.20761001e-02,  8.82327198e+00,\n",
       "        -8.73708578e+00, -2.17370390e+00, -9.08313978e+00, -9.21571081e-03,\n",
       "         1.08744528e+01, -9.28339536e+00, -9.84994253e-01,  1.26577246e+00,\n",
       "         4.12701113e-04,  1.14959956e+01, -9.04022765e-01, -4.81667360e+00,\n",
       "        -5.09743452e+00,  5.98719652e-03,  1.08994485e+01,  1.88757078e+00,\n",
       "         2.43284306e+00, -5.65553602e+00, -5.85863998e-04,  2.55489989e+01,\n",
       "         1.67232072e+00, -4.48701283e+00, -1.38737513e+01, -5.45691425e-03,\n",
       "         1.88963435e+01, -3.42837877e-01,  5.51895708e+00, -2.95050522e+01,\n",
       "         6.51061191e-03, -4.33481423e-01, -4.18911934e+00, -6.42131541e+00,\n",
       "        -1.67658320e+01, -4.30074512e-03, -8.13695280e-01, -3.92299221e+00,\n",
       "         1.14899468e+00,  9.52972938e+00, -1.08706408e-02, -1.87476489e+01,\n",
       "         1.24773537e+01,  4.78340178e+00, -4.94959220e+00,  6.53422753e-03,\n",
       "        -7.45431222e-01, -8.58108710e-01,  2.62802260e+00,  2.22775382e+00,\n",
       "        -8.75046057e-03, -6.37375010e+00, -2.47135462e+00,  9.66413377e+00,\n",
       "         2.16183239e+00,  1.05484259e-02, -1.80483817e+01, -6.38843161e+00,\n",
       "         2.11265218e+00,  3.88557391e+00,  6.66767797e-03,  6.55572839e+00,\n",
       "         6.35099474e-01, -9.60124467e+00,  1.85578919e+01,  1.18212743e-02,\n",
       "         1.51294063e+00,  1.14375650e+01, -7.12759356e+00,  5.25226045e-01,\n",
       "        -1.65967414e-02,  4.44645463e+00, -3.57277090e+00, -1.20886909e+01,\n",
       "         2.58799188e+00, -4.35440711e-04, -6.90460344e+00, -6.70798538e+00,\n",
       "         5.96354813e+00,  6.15919675e+00,  4.24450185e-03,  2.50858458e+01,\n",
       "        -2.87935989e+00, -1.14563478e+00,  1.26430268e+01,  2.70910999e-03,\n",
       "        -2.26735719e-01,  2.43223199e+00, -7.88397207e+00, -2.72590962e+01,\n",
       "        -1.16428702e-02,  2.44924717e+01,  1.29399835e+00,  6.08898929e+00,\n",
       "         5.76683555e+00,  1.62814624e-02,  1.43450059e+01,  9.39605853e+00,\n",
       "        -7.92773201e+00, -3.31421433e+01, -1.98480381e-02, -1.86656899e+00,\n",
       "         2.43412279e+00,  1.25999384e+01, -2.79425182e+01,  5.66681479e-03,\n",
       "         5.12286659e-01, -6.28546682e+00, -4.23438181e+00,  1.47296778e+00,\n",
       "        -2.79919305e-03, -6.52755086e-01,  2.52447088e+00,  7.00327477e+00,\n",
       "         1.72658221e+00,  6.28387975e-03, -4.75418832e+00, -2.44663464e-01,\n",
       "        -1.97798350e-01, -6.50868319e+00, -1.27597395e-02, -1.43144826e+01,\n",
       "        -4.85456857e+00, -3.86432288e+00,  1.43755607e+01, -8.86411812e-03,\n",
       "         4.59720028e+00,  4.96276854e+00, -7.20396448e+00,  2.34505006e+01,\n",
       "        -3.20924776e-03, -8.97382138e+00,  1.73525499e+00, -5.30523433e+00,\n",
       "        -2.47712516e+00, -1.39154346e-03,  5.96002150e+00,  4.39372569e+00,\n",
       "         1.96978231e+00,  4.67026564e+00,  1.04562031e-02, -6.11145561e+00,\n",
       "         1.35403122e+01, -3.77510895e+00, -1.45640434e+01, -2.39477828e-02,\n",
       "        -1.44753405e+01, -7.79237615e+00,  1.40104632e+00,  3.78556433e+00,\n",
       "         1.66209042e-02, -1.97274135e+00,  2.23160997e+00,  2.72151345e+00,\n",
       "         1.58488237e+01, -8.77301622e-05,  2.24201549e+01, -1.39483020e+01,\n",
       "         9.33983682e+00,  4.16090499e+00,  1.38746694e-02,  4.18928397e-01,\n",
       "        -1.22148308e+01, -3.14073789e+00, -1.45987236e+01,  2.43210550e-03,\n",
       "        -1.06574704e+01,  1.90496496e+00,  1.86166996e+00,  3.82028657e+00,\n",
       "        -4.87092624e-03,  2.19304014e+01, -5.00118368e+00,  3.59097262e+00,\n",
       "         9.36214766e+00,  2.67164908e-02,  2.45090677e-03, -8.09782351e-03,\n",
       "        -2.41267137e-03, -7.31914879e-03, -1.31844531e-02,  3.82028657e+00]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting a linear regression model\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "linmodel = LinearRegression()\n",
    "linmodel.fit(X_train_scaled, y_train)\n",
    "linmodel.intercept_, linmodel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b09989",
   "metadata": {},
   "source": [
    "Because there are so many features, we can see that the list of coefficients is very long. It is likely that the linear reegression will overfit because it will try to fit all of the features, even if they are not relevant. After seeing performance, we will reduce the number of features to see if this improves out of sample performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 0.15\n",
      "R^2 on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "# see how it performs on out of sample data\n",
    "y_hat = linmodel.predict(X_test_scaled)\n",
    "error = np.sqrt(np.mean((y_hat - y_test) ** 2))\n",
    "print(f\"RMSE on test set: {error:.2f}\")\n",
    "#print r2 score\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "print(f\"R^2 on test set: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a8923",
   "metadata": {},
   "source": [
    "The RMSE is quite low, at .15. The r squared is also extremely high at 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479db4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 318)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only columns that have '_-t1' -t2 or -t3 in them\n",
    "new_features = ['Open_t-1', 'Close_t-1', 'Volume_t-1', 'High_t-1', 'Low_t-1',\n",
    "                'Open_t-2', 'Close_t-2', 'Volume_t-2', 'High_t-2', 'Low_t-2',\n",
    "                'Open_t-3', 'Close_t-3', 'Volume_t-3', 'High_t-3', 'Low_t-3'] + ['Open_t0']\n",
    "X_new_train = X_train[feature_cols]\n",
    "X_new_test = X_test[feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1261a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set with new features: 0.15\n",
      "R^2 on test set with new features: 1.00\n"
     ]
    }
   ],
   "source": [
    "#now fitting new linear regression\n",
    "linmodel_new = LinearRegression()\n",
    "linmodel_new.fit(X_new_train, y_train)\n",
    "# see how it performs on out of sample data\n",
    "y_new_hat = linmodel_new.predict(X_new_test)\n",
    "new_error = np.sqrt(np.mean((y_new_hat - y_test) ** 2))\n",
    "print(f\"RMSE on test set with new features: {new_error:.2f}\")\n",
    "# print r2 score\n",
    "new_r2 = r2_score(y_test, y_new_hat)\n",
    "print(f\"R^2 on test set with new features: {new_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de05c0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d234fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c7de95",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda88ff",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fb153",
   "metadata": {},
   "source": [
    "## One more model I forget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004ec4c",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4170d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
