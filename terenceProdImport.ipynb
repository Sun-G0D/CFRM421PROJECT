{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFRM 421 Final Proejct - Terence Chiu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the goal of your project?\n",
    "\n",
    "• What is the data that you are using? What is the original data source if known?\n",
    "\n",
    "• What does an instance in your data represent (e.g. a person, a transaction, etc.)? How many\n",
    "instances are there?\n",
    "\n",
    "• What is the target variable you are trying to predict?\n",
    "\n",
    "• What are the features used to predict it? Give a few examples of the features.\n",
    "\n",
    "• Provide any additional relevant information about your data if known (e.g. what is the time\n",
    "period, what place is it collected from, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from terenceModel import DNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN  \n",
    "Inputs:\n",
    "- Weekly Import\n",
    "- Weekly Production\n",
    "- Weekly Supply\n",
    "- Crude Oil Futures Price 1-2 minutes before release  \n",
    "\n",
    "Outputs (predict): \n",
    "- Futures Price 1-2 minutes after release\n",
    "\n",
    "Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plot method to compare predicted and actual price at T+2 minutes after weekly report release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"full_data.csv\")\n",
    "\n",
    "feature_cols = [col for col in df.columns if 'Close_t-60'  in col or 'Close_t-40' in col or 'Close_t-20' in col or col == 'Release Date' or col == 'Actual' or col == 'Weekly Net Import' or col == 'Weekly Production' or col == 'Open_t0']\n",
    "\n",
    "X_temp = df[feature_cols]\n",
    "y_temp = df['Close_t2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Release Date',\n",
       " 'Close_t-60',\n",
       " 'Close_t-40',\n",
       " 'Close_t-20',\n",
       " 'Open_t0',\n",
       " 'Actual',\n",
       " 'Weekly Net Import',\n",
       " 'Weekly Production']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_weekly = X_temp[['Release Date', 'Weekly Production']]\n",
    "net_import_weekly = X_temp[['Release Date', 'Weekly Net Import']]\n",
    "supply_weekly = X_temp[['Release Date', 'Actual']]\n",
    "price_wide = X_temp[['Release Date', 'Close_t-60', 'Close_t-40', 'Close_t-20', 'Open_t0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/xcbt_9650nz8tknq733z87640000gn/T/ipykernel_10787/1514931792.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_features[col] = price_scaler.fit_transform(price_wide[col].values.reshape(-1, 1)).flatten()\n",
      "/var/folders/vl/xcbt_9650nz8tknq733z87640000gn/T/ipykernel_10787/1514931792.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_features[col] = price_scaler.fit_transform(price_wide[col].values.reshape(-1, 1)).flatten()\n",
      "/var/folders/vl/xcbt_9650nz8tknq733z87640000gn/T/ipykernel_10787/1514931792.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_features[col] = price_scaler.fit_transform(price_wide[col].values.reshape(-1, 1)).flatten()\n",
      "/var/folders/vl/xcbt_9650nz8tknq733z87640000gn/T/ipykernel_10787/1514931792.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_features[col] = price_scaler.fit_transform(price_wide[col].values.reshape(-1, 1)).flatten()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "price_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "price_features = price_wide[['Close_t-60', 'Close_t-40', 'Close_t-20', 'Open_t0']]\n",
    "\n",
    "# Scale the price features in the dataframe\n",
    "for col in ['Close_t-60', 'Close_t-40', 'Close_t-20', 'Open_t0']:\n",
    "    price_features[col] = price_scaler.fit_transform(price_wide[col].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Scale the target values in the dataframe\n",
    "y_temp = target_scaler.fit_transform(y_temp.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaler for weekly data\n",
    "weekly_scaler = StandardScaler()\n",
    "\n",
    "weekly_production_scaled = weekly_scaler.fit_transform(prod_weekly['Weekly Production'].values.reshape(-1, 1)).flatten()\n",
    "weekly_import_scaled = weekly_scaler.fit_transform(net_import_weekly['Weekly Net Import'].values.reshape(-1, 1)).flatten()\n",
    "weekly_supply_scaled = weekly_scaler.fit_transform(supply_weekly['Actual'].values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, row in price_features.iterrows():\n",
    "    # Target: price of future 2 minutes after release (already scaled)\n",
    "    target_price = y_temp[idx]\n",
    "\n",
    "    \n",
    "    production_value = weekly_production_scaled[idx]\n",
    "    import_value = weekly_import_scaled[idx]\n",
    "    supply_value = weekly_supply_scaled[idx]\n",
    "    production_value = production_value\n",
    "    import_value = import_value\n",
    "    supply_value = supply_value\n",
    "\n",
    "    row_data = [price_features['Close_t-60'].values[idx],price_features['Close_t-40'].values[idx],price_features['Close_t-20'].values[idx],price_features['Open_t0'].values[idx],production_value,import_value,supply_value]\n",
    "    X.append(row_data)\n",
    "    y.append(target_price)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terenceModel import DNN\n",
    "from terenceTrainModel import plot_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based 80/20 split\n",
    "n = len(X)\n",
    "split_idx = int(n * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DNN.train() got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[181]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m model = DNN()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train model with sample weights\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m trained_model, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weights_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Predict on test set\u001b[39;00m\n\u001b[32m     12\u001b[39m y_pred = trained_model.predict(X_test).flatten()\n",
      "\u001b[31mTypeError\u001b[39m: DNN.train() got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "# Compute sample weights for training and test sets\n",
    "epsilon = 1e-6\n",
    "sample_weights_train = np.abs(y_train) + epsilon\n",
    "sample_weights_test = np.abs(y_test) + epsilon\n",
    "\n",
    "model = DNN()\n",
    "\n",
    "# Train model with sample weights\n",
    "trained_model, _ = model.train(X_train, y_train, sample_weight=sample_weights_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = trained_model.predict(X_test).flatten()\n",
    "\n",
    "# Weighted RMSE for test set\n",
    "weighted_test_rmse = np.sqrt(mean_squared_error(y_test, y_pred, sample_weight=sample_weights_test))\n",
    "print(f\"Weighted Test RMSE: {weighted_test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test MAE (unscaled) between predicted and actual prices after two minutes of weekly report release is 1.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model predicts the price given momentum of price the hour before report release, and THE report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
